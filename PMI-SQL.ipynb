{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "\n",
    "lines = spark.read.text('wasb://cluster@msbd.blob.core.windows.net/data/adj_noun_pairs.txt')\n",
    "lines.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Converting lines into word pairs. \n",
    "# Data is dirty: some lines have more than 2 words, so filter them out.\n",
    "# pairs = lines.map(lambda l: tuple(l.split())).filter(lambda p: len(p)==2)\n",
    "words = lines.select(split(lines[0],' ').alias('w')).filter(size('w')==2) \n",
    "pairs = words.select(words['w'][0].alias('adj'), words['w'][1].alias('noun'))\n",
    "pairs.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pairs.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N = pairs.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Compute the frequency of each pair.\n",
    "# Ignore pairs that not frequent enough\n",
    "# pair_freqs = pairs.map(lambda p: (p,1)).reduceByKey(lambda f1, f2: f1 + f2) \\\n",
    "#                   .filter(lambda pf: pf[1] >= 100)\n",
    "\n",
    "pair_freqs = pairs.groupBy('adj', 'noun').count().filter('count >= 100')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pair_freqs.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Computing the frequencies of the adjectives and the nouns\n",
    "# a_freqs = pairs.map(lambda p: (p[0],1)).reduceByKey(lambda x,y: x+y)\n",
    "# n_freqs = pairs.map(lambda p: (p[1],1)).reduceByKey(lambda x,y: x+y)\n",
    "\n",
    "a_freqs =  pairs.groupBy('adj').count().withColumnRenamed('count', 'adjcount')\n",
    "n_freqs =  pairs.groupBy('noun').count().withColumnRenamed('count', 'nouncount')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a_freqs.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pair_freqs.join(a_freqs, 'adj').join(n_freqs, 'noun') \\\n",
    "          .select('adj', 'noun', \n",
    "                  log2(col('count')*N/(col('adjcount')*col('nouncount')))\n",
    "                  .alias('PMI')) \\\n",
    "          .orderBy(desc('PMI')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 2
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}